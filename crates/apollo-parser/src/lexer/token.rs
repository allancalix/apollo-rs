use std::fmt;

use crate::TokenKind;

/// A token generated by the lexer.
#[derive(Clone)]
pub struct Token {
    pub(crate) start_index: u32,
    pub(crate) end_index: u16,
    pub(crate) kind: TokenKind,
}

impl Token {
    pub(crate) fn new(kind: TokenKind, data: &str) -> Self {
        Self {
            kind,
            start_index: 0,
            end_index: data.len() as u16,
        }
    }

    /// Get a reference to the token's kind.
    pub fn kind(&self) -> TokenKind {
        self.kind
    }

    /// Get a reference to the token's data.
    #[inline(always)]
    pub fn data<'a>(&self, src: &'a str) -> &'a str {
        &src[self.start_index as usize..self.end_index as usize]
    }

    pub fn with_data(&mut self, src: &str) {
        self.end_index = (self.start_index + src.len() as u32) as u16;
    }

    /// Get a reference to the token's loc.
    #[inline(always)]
    pub fn index(&self) -> usize {
        self.start_index as usize
    }
}

impl fmt::Debug for Token {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        let start = self.start_index;
        let end = self.end_index;

        write!(f, "WHITESPACE@{}:{}", start, end)
        // match &self.kind {
        //     TokenKind::Whitespace => {
        //         write!(f, "WHITESPACE@{}:{} {:?}", start, end, self.data)
        //     }
        //     TokenKind::Comment => {
        //         write!(f, "COMMENT@{}:{} {:?}", start, end, self.data)
        //     }
        //     TokenKind::Bang => {
        //         write!(f, "BANG@{}:{} {:?}", start, end, self.data)
        //     }
        //     TokenKind::Dollar => {
        //         write!(f, "DOLLAR@{}:{} {:?}", start, end, self.data)
        //     }
        //     TokenKind::Amp => {
        //         write!(f, "AMP@{}:{} {:?}", start, end, self.data)
        //     }
        //     TokenKind::Spread => {
        //         write!(f, "SPREAD@{}:{} {:?}", start, end, self.data)
        //     }
        //     TokenKind::Colon => {
        //         write!(f, "COLON@{}:{} {:?}", start, end, self.data)
        //     }
        //     TokenKind::Comma => {
        //         write!(f, "COMMA@{}:{} {:?}", start, end, self.data)
        //     }
        //     TokenKind::Eq => {
        //         write!(f, "EQ@{}:{} {:?}", start, end, self.data)
        //     }
        //     TokenKind::At => {
        //         write!(f, "AT@{}:{} {:?}", start, end, self.data)
        //     }
        //     TokenKind::LParen => {
        //         write!(f, "L_PAREN@{}:{} {:?}", start, end, self.data)
        //     }
        //     TokenKind::RParen => {
        //         write!(f, "R_PAREN@{}:{} {:?}", start, end, self.data)
        //     }
        //     TokenKind::LBracket => {
        //         write!(f, "L_BRACKET@{}:{} {:?}", start, end, self.data)
        //     }
        //     TokenKind::RBracket => {
        //         write!(f, "R_BRACKET@{}:{} {:?}", start, end, self.data)
        //     }
        //     TokenKind::LCurly => {
        //         write!(f, "L_CURLY@{}:{} {:?}", start, end, self.data)
        //     }
        //     TokenKind::RCurly => {
        //         write!(f, "R_CURLY@{}:{} {:?}", start, end, self.data)
        //     }
        //     TokenKind::Pipe => {
        //         write!(f, "PIPE@{}:{} {:?}", start, end, self.data)
        //     }
        //     TokenKind::Eof => {
        //         write!(f, "EOF@{start}:{start}")
        //     }

        //     // composite nodes
        //     TokenKind::Name => {
        //         write!(f, "NAME@{}:{} {:?}", start, end, self.data)
        //     }
        //     TokenKind::StringValue => {
        //         write!(f, "STRING_VALUE@{}:{} {:?}", start, end, self.data)
        //     }
        //     TokenKind::Int => {
        //         write!(f, "INT@{}:{} {:?}", start, end, self.data)
        //     }
        //     TokenKind::Float => {
        //         write!(f, "FLOAT@{}:{} {:?}", start, end, self.data)
        //     }
        // }
    }
}
